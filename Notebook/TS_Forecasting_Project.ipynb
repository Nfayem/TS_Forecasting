{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAVORITA STORES SALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Table-of-Contents)\n",
    "\n",
    "## Step 1: Business Understanding\n",
    "\n",
    "### **Project Background:** \n",
    "This project focuses on time series forecasting to predict store sales for Corporation Favorita, a large Ecuadorian-based grocery retailer. The objective is to build a model that accurately predicts the unit sales for thousands of items sold at different Favorita stores.\n",
    "\n",
    "### **Project Objective:** \n",
    "The project will focus on two areas:\n",
    "- Understand the data: The first objective is to gain insights into the store sales data, including store-specific information, product families, promotions, and sales numbers. This understanding will enable the company to make informed business decisions.\n",
    "\n",
    "- Predict store sales: Develop a reliable time series forecasting model that accurately predicts the unit sales for different product families at various Favorita stores. This will help the company optimize inventory management, plan promotions, and improve overall sales performance.\n",
    "\n",
    "### **Methdology:** \n",
    "\n",
    "To achieve the objectives, we will follow a structured approach:\n",
    "\n",
    "- Data Exploration: Thoroughly explore the provided datasets to understand the available features, their distributions, and relationships. This step will provide initial insights into the store sales data and help identify any data quality issues.\n",
    "\n",
    "- Data Preparation: Handle missing values, perform feature engineering, and encode categorical variables as necessary. This step may involve techniques like imputation, scaling, and one-hot encoding.\n",
    "\n",
    "- Time Series Analysis: Analyze the temporal aspects of the data, including trends, seasonality, and potential outliers. This analysis will provide a deeper understanding of the underlying patterns in store sales over time.\n",
    "\n",
    "- Model Selection and Training: Select appropriate time series forecasting models and train them using the prepared data. Consider incorporating external factors like promotions, holidays, and oil prices, if available, to enhance the forecasting accuracy.\n",
    "\n",
    "- Model Evaluation: Evaluate the trained models using appropriate metrics, such as mean absolute error (MAE), root mean squared error (RMSE), or mean absolute percentage error (MAPE). Assess the models' performance and identify the most accurate and reliable forecasting model.\n",
    "\n",
    "- Model Deployment and Forecasting: Deploy the chosen model to predict store sales for future time periods, leveraging the provided test dataset. Generate forecasts for the target period and assess the model's ability to capture the sales patterns accurately.\n",
    "\n",
    "By following this framework, we are going to predict store sales of Corporation Favorita.\n",
    "\n",
    "### **File Descriptions and Data Field Information**\n",
    "\n",
    "**train.csv**\n",
    "\n",
    "-   The training data, comprising time series of features store_nbr, family, \n",
    "    and onpromotion as well as the target sales.\n",
    "\n",
    "-   **store_nbr** identifies the store at which the products are sold.\n",
    "\n",
    "-   **family** identifies the type of product sold.\n",
    "\n",
    "-   **sales** gives the total sales for a product family at a particular store\n",
    "    at a given date. Fractional values are possible since products can be sold in \n",
    "    fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
    "\n",
    "-   **onpromotion** gives the total number of items in a product family that\n",
    "    were being promoted at a store at a given date.\n",
    "\n",
    "**test.csv**\n",
    "\n",
    "-   The test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n",
    "\n",
    "-   The dates in the test data are for the 15 days after the last date in the training data.\n",
    "\n",
    "**transaction.csv**\n",
    "\n",
    "-   Contains date, store_nbr and transaction made on that specific date.\n",
    "\n",
    "**sample_submission.csv**\n",
    "\n",
    "-   A sample submission file in the correct format.\n",
    "\n",
    "**stores.csv**\n",
    "\n",
    "-   Store metadata, including city, state, type, and cluster.\n",
    "\n",
    "-   cluster is a grouping of similar stores.\n",
    "\n",
    "**oil.csv**\n",
    "\n",
    "-   **Daily oil price** which includes values during both the train and\n",
    "     test data timeframes. (Ecuador is an oil-dependent country and its\n",
    "     economical health is highly vulnerable to shocks in oil prices.)\n",
    "\n",
    "**holidays_events.csv**\n",
    "\n",
    "-   Holidays and Events, with metadata\n",
    "\n",
    "> **NOTE**: Pay special attention to the transferred column. A holiday\n",
    "> that is transferred officially falls on that calendar day but was\n",
    "> moved to another date by the government. A transferred day is more\n",
    "> like a normal day than a holiday. To find the day that it was\n",
    "> celebrated, look for the corresponding row where type is **Transfer**.\n",
    ">\n",
    "> For example, the holiday Independencia de Guayaquil was transferred\n",
    "> from 2012-10-09 to 2012-10-12, which means it was celebrated on\n",
    "> 2012-10-12. Days that are type **Bridge** are extra days that are\n",
    "> added to a holiday (e.g., to extend the break across a long weekend).\n",
    "> These are frequently made up by the type **Work Day** which is a day\n",
    "> not normally scheduled for work (e.g., Saturday) that is meant to\n",
    "> payback the Bridge.\n",
    "\n",
    "-   Additional holidays are days added a regular calendar holiday, for\n",
    "    example, as typically happens around Christmas (making Christmas\n",
    "    Eve a holiday).\n",
    "\n",
    "**Additional Notes**\n",
    "\n",
    "-   Wages in the public sector are paid every two weeks on the 15th and\n",
    "    on the last day of the month. Supermarket sales could be affected\n",
    "    by this.\n",
    "\n",
    "-   A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People\n",
    "    rallied in relief efforts donating water and other first need\n",
    "    products which greatly affected supermarket sales for several\n",
    "    weeks after the earthquake.\n",
    "\n",
    "\n",
    "### **Hypothesis:** \n",
    "\n",
    "**Null Hypothesis (H<sub>0</sub>):**\n",
    "Promotions have no effect on sales.\n",
    "\n",
    "**Alternative Hypothesis (H<sub>1</sub>):**\n",
    "Promotions have a positive effect on sales.\n",
    "\n",
    "### **Key Business Questions:**\n",
    "\n",
    "1. **Is the train dataset complete (has all the required dates)?**\n",
    "\n",
    "   **Purpose:** Ensuring data integrity and comprehensiveness is crucial for accurate forecasting and analysis. Missing dates can lead to incomplete models and incorrect insights.\n",
    "   \n",
    "   **Approach:** \n",
    "   - Verify the presence of all expected dates within the dataset.\n",
    "   - Identify and address any missing dates using imputation methods or flagging them for further investigation.\n",
    "   - Utilize time series analysis techniques to check for continuity and consistency in the dataset.\n",
    "\n",
    "2. **Which dates have the lowest and highest sales for each year (excluding days the store was closed)?**\n",
    "\n",
    "   **Purpose:** Identifying peak and low sales periods helps in understanding seasonal trends and planning inventory, promotions, and staffing.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Aggregate sales data by date and year.\n",
    "   - Use descriptive statistics to identify the dates with the minimum and maximum sales for each year.\n",
    "   - Visualize the results using time series plots to highlight trends and anomalies.\n",
    "\n",
    "3. **Did the earthquake impact sales?**\n",
    "\n",
    "   **Purpose:** Assessing the impact of external events on sales is critical for risk management and contingency planning.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Analyze sales data before, during, and after the earthquake period.\n",
    "   - Use statistical tests (e.g., t-tests, ANOVA) to determine if there are significant differences in sales during these periods.\n",
    "   - Control for other variables that might influence sales to isolate the effect of the earthquake.\n",
    "\n",
    "4. **Are certain stores or certain groups of stores selling more products? (Cluster, city, state, type)**\n",
    "\n",
    "   **Purpose:** Understanding regional and store-type performance aids in targeted marketing and resource allocation.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Segment stores by clusters, cities, states, and types.\n",
    "   - Perform comparative analysis using descriptive statistics and visualizations (e.g., box plots, bar charts).\n",
    "   - Use statistical tests to determine if there are significant differences in sales among the different groups.\n",
    "\n",
    "5. **Are sales affected by promotions, oil prices, and holidays?**\n",
    "\n",
    "   **Purpose:** Identifying key drivers of sales enables better forecasting and strategy development.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Collect data on promotions, oil prices, and holidays.\n",
    "   - Perform correlation analysis and regression modeling to assess the impact of these factors on sales.\n",
    "   - Use time series analysis to account for seasonality and trends.\n",
    "\n",
    "6. **What analysis can we get from the date and its extractable features?**\n",
    "\n",
    "   **Purpose:** Extracting and analyzing date-related features helps in understanding temporal patterns and improving forecasting models.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Extract features such as day of the week, month, quarter, and holidays from the date.\n",
    "   - Analyze how these features correlate with sales using statistical and machine learning methods.\n",
    "   - Use feature importance techniques in predictive modeling to identify the most impactful date-related features.\n",
    "\n",
    "7. **What is the difference between RMSLE, RMSE, MSE (or why is the MAE greater than all of them)?**\n",
    "\n",
    "   **Purpose:** Understanding different evaluation metrics is essential for selecting the appropriate method to measure model performance.\n",
    "   \n",
    "   **Approach:**\n",
    "   - Define and explain the formulas and use cases for RMSLE (Root Mean Squared Logarithmic Error), RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error).\n",
    "   - Compare the metrics using examples or model results to highlight their differences.\n",
    "   - Discuss why MAE might be greater than RMSLE, RMSE, and MSE in certain contexts, focusing on sensitivity to outliers and the nature of error penalization.\n",
    "\n",
    "8. **Compare the sales for each month across the years and determine which month of which year had the highest sales.**\n",
    "\n",
    "9. **Which product family and stores did the promotions affect?**\n",
    "    \n",
    "10. **Does the payment of wages in the public sector on the 15th and last days of the month influence the store sales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Table-of-Contents)\n",
    "## Step 2: Data Understanding\n",
    "\n",
    "`Project Initialization`\n",
    "\n",
    "`Data Collection`\n",
    "\n",
    "`EDA & Data Cleaning`\n",
    "\n",
    "Inspect the dataset in depth, visualise it to answer analytical questions and plan the cleaning, processing and feature creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables management\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Database connection\n",
    "import pyodbc\n",
    "import MySQLdb\n",
    "import mysql.connector\n",
    "import pymysql\n",
    "\n",
    "# Data handling and utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import calendar\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Data fetching\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import skew, kurtosis, chi2_contingency\n",
    "\n",
    "# Time series analysis\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "# from fbprophet import Prophet\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, display_html\n",
    "\n",
    "# Data imputation\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer, enable_halving_search_cv\n",
    "\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "# Feature processing\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, LabelEncoder, \n",
    "    FunctionTransformer, OneHotEncoder, RobustScaler, PowerTransformer, quantile_transform\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedShuffleSplit, \n",
    "    GridSearchCV, RandomizedSearchCV, cross_val_score, \n",
    "    cross_val_predict, TimeSeriesSplit\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample, estimator_html_repr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, chi2, f_classif, \n",
    "    mutual_info_classif, RFE, SelectFromModel, SelectPercentile\n",
    ")\n",
    "\n",
    "# Machine Learning models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Neural Networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, make_scorer, \n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, \n",
    "    f1_score, log_loss, roc_curve, mean_squared_error, mean_absolute_error\n",
    ")\n",
    "\n",
    "# Suppressing warnings to avoid cluttering the output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set display options for Pandas DataFrame\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Set theme for plots\n",
    "sns.set_theme(style=\"white\", palette=\"pastel\", font=\"sans-serif\", font_scale=1.5)\n",
    "plt.style.use(\"default\")\n",
    "custom_palette = [\"cyan\", \"magenta\", \"yellow\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "The task involves accessing three different datasets from different sources: a database, OneDrive, and a GitHub repository. Each dataset has a specific method of access, such as querying a database using ODBC or ORM library, downloading a file programmatically using the requests library from OneDrive, and cloning or downloading a file from a GitHub repository using gitpython or requests library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access the LP3_TS_forecasting databases from Microsoft SQL Server\n",
    "Connect to the database using provided credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful: DRIVER={SQL Server};SERVER=dap-projects-database.database.windows.net;DATABASE=dapDB;UID=learning_project_3;PWD=A$uB1Lp3$2@24\n"
     ]
    }
   ],
   "source": [
    "# load environment variables from.env file into dictionary\n",
    "environment_variables = dotenv_values(\"LP3_TSF.env\")\n",
    "\n",
    "# get the values for the environment variables\n",
    "server = environment_variables.get(\"server\")\n",
    "login = environment_variables.get(\"login\")\n",
    "password = environment_variables.get(\"password\")\n",
    "database = environment_variables.get(\"database\")\n",
    "\n",
    "# Create a database connection string using pyodbc\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={login};PWD={password}\"\n",
    "#Establish a connection to the database\n",
    "try:\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    print(\"Connection successful:\", connection_string)    \n",
    "except Exception as e:\n",
    "    print(\"Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetch Information Schema for tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved successfully\n",
      "\n",
      "  TABLE_CATALOG TABLE_SCHEMA       TABLE_NAME  TABLE_TYPE\n",
      "0         dapDB          dbo  holidays_events  BASE TABLE\n",
      "1         dapDB          dbo              oil  BASE TABLE\n",
      "2         dapDB          dbo           stores  BASE TABLE\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query to show specific tables in the database\n",
    "db_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM INFORMATION_SCHEMA.TABLES\n",
    "        WHERE TABLE_SCHEMA = 'dbo'\n",
    "        \"\"\"\n",
    "# Read data from the SQL query result into a DataFrame using the established database connection\n",
    "schema_df = pd.read_sql(db_query, connection)\n",
    "\n",
    "#  Check whether data has been retrieved successfully to confirm successful connection to database\n",
    "try:\n",
    "    schema_df = pd.read_sql(db_query, connection)    \n",
    "    print(\"Data retrieved successfully\")\n",
    "    print()\n",
    "    print(schema_df)    \n",
    "except Exception as e:\n",
    "    print(\"Failed to retrieve data:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting stores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr           city                           state type  cluster\n",
       "0          1          Quito                       Pichincha    D       13\n",
       "1          2          Quito                       Pichincha    D       13\n",
       "2          3          Quito                       Pichincha    D        8\n",
       "3          4          Quito                       Pichincha    D        9\n",
       "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SQL query to show specific tables in the database\n",
    "db_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM stores        \n",
    "        \"\"\"\n",
    "# Read data from the SQL query result into a DataFrame using the established database connection\n",
    "df_stores = pd.read_sql(db_query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting oil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.199997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico\n",
       "0  2013-01-01         NaN\n",
       "1  2013-01-02   93.139999\n",
       "2  2013-01-03   92.970001\n",
       "3  2013-01-04   93.120003\n",
       "4  2013-01-07   93.199997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SQL query to show specific tables in the database\n",
    "db_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM oil        \n",
    "        \"\"\"\n",
    "# Read data from the SQL query result into a DataFrame using the established database connection\n",
    "df_oil = pd.read_sql(db_query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_oil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting holidays_events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type    locale locale_name                    description  \\\n",
       "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SQL query to show specific tables in the database\n",
    "db_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM holidays_events        \n",
    "        \"\"\"\n",
    "# Read data from the SQL query result into a DataFrame using the established database connection\n",
    "df_holidays = pd.read_sql(db_query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access the LP3_TS_forecasting databases from GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "File extracted successfully\n"
     ]
    }
   ],
   "source": [
    "# URL of the file to download\n",
    "url = \"https://github.com/Nfayem/Career_Accelerator_LP3-Regression/raw/main/store-sales-forecasting.zip\"\n",
    "\n",
    "# Local file path where the file will be saved\n",
    "local_file_path = '../Data/store-sales-forecasting.zip'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Write the content of the response to the specified file path\n",
    "    with open(local_file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"File downloaded successfully\")\n",
    "    \n",
    "    # Extract the ZIP file\n",
    "    with zipfile.ZipFile(local_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(local_file_path))\n",
    "    print(\"File extracted successfully\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the downloaded CSV file into a DataFrame\n",
    "df_train = pd.read_csv('../Data/train.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_train.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store_nbr  transactions\n",
       "0  2013-01-01         25           770\n",
       "1  2013-01-02          1          2111\n",
       "2  2013-01-02          2          2358\n",
       "3  2013-01-02          3          3487\n",
       "4  2013-01-02          4          1922"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the downloaded CSV file into a DataFrame\n",
    "df_transactions = pd.read_csv('../Data/transactions.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access LP3_TS_forecasting databases from OneDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting sample_submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sales\n",
       "0  3000888    0.0\n",
       "1  3000889    0.0\n",
       "2  3000890    0.0\n",
       "3  3000891    0.0\n",
       "4  3000892    0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the downloaded CSV file into a DataFrame\n",
    "df_sample = pd.read_csv('../Data/sample_submission.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_sample.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load LP3_TS_forecasting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr      family  onpromotion\n",
       "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1   BABY CARE            0\n",
       "2  3000890  2017-08-16          1      BEAUTY            2\n",
       "3  3000891  2017-08-16          1   BEVERAGES           20\n",
       "4  3000892  2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the downloaded CSV file into a DataFrame\n",
    "df_test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "#### A. Data Quality Assessment & Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   store_nbr  54 non-null     int64 \n",
      " 1   city       54 non-null     object\n",
      " 2   state      54 non-null     object\n",
      " 3   type       54 non-null     object\n",
      " 4   cluster    54 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_stores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1218 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_oil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_holidays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000888 entries, 0 to 3000887\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   id           int64  \n",
      " 1   date         object \n",
      " 2   store_nbr    int64  \n",
      " 3   family       object \n",
      " 4   sales        float64\n",
      " 5   onpromotion  int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 137.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          83488 non-null  object\n",
      " 1   store_nbr     83488 non-null  int64 \n",
      " 2   transactions  83488 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      28512 non-null  int64  \n",
      " 1   sales   28512 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 445.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           28512 non-null  int64 \n",
      " 1   date         28512 non-null  object\n",
      " 2   store_nbr    28512 non-null  int64 \n",
      " 3   family       28512 non-null  object\n",
      " 4   onpromotion  28512 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatype and the number of columns\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        1218 non-null   datetime64[ns]\n",
      " 1   dcoilwtico  1175 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 19.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df_oil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         350 non-null    datetime64[ns]\n",
      " 1   type         350 non-null    object        \n",
      " 2   locale       350 non-null    object        \n",
      " 3   locale_name  350 non-null    object        \n",
      " 4   description  350 non-null    object        \n",
      " 5   transferred  350 non-null    bool          \n",
      "dtypes: bool(1), datetime64[ns](1), object(4)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_holidays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000888 entries, 0 to 3000887\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   store_nbr    int64         \n",
      " 3   family       object        \n",
      " 4   sales        float64       \n",
      " 5   onpromotion  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(1)\n",
      "memory usage: 137.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          83488 non-null  datetime64[ns]\n",
      " 1   store_nbr     83488 non-null  int64         \n",
      " 2   transactions  83488 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_transactions['date'] = pd.to_datetime(df_transactions['date'])\n",
    "df_transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   id           28512 non-null  int64         \n",
      " 1   date         28512 non-null  datetime64[ns]\n",
      " 2   store_nbr    28512 non-null  int64         \n",
      " 3   family       28512 non-null  object        \n",
      " 4   onpromotion  28512 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame to preserve the original data\n",
    "df_train_eda = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values in df_train dataset:\n",
      "\n",
      "id             0.0\n",
      "date           0.0\n",
      "store_nbr      0.0\n",
      "family         0.0\n",
      "sales          0.0\n",
      "onpromotion    0.0\n",
      "dtype: float64\n",
      "\n",
      "Number of duplicated rows in df_train dataset: 0\n",
      "\n",
      "Duplicated rows in the df_train dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, store_nbr, family, sales, onpromotion]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the proportion of missing values\n",
    "missing_percentage = (df_train_eda.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Check for duplicated values\n",
    "duplicate_count = df_train_eda.duplicated(subset=None, keep=False).sum()\n",
    "\n",
    "# Display duplicated rows if any\n",
    "duplicated_rows = df_train_eda[df_train_eda.duplicated(subset=None, keep=False)]\n",
    "\n",
    "# Display Results\n",
    "print(\"Proportion of missing values in df_train dataset:\")\n",
    "print()\n",
    "print(missing_percentage)\n",
    "print(\"\\nNumber of duplicated rows in df_train dataset:\", duplicate_count)\n",
    "print(\"\\nDuplicated rows in the df_train dataset:\")\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df_train_eda.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "There are 3000888 unique values\n",
      "[      0       1       2 ... 3000885 3000886 3000887]\n",
      "______________________________________________________________________\n",
      "date\n",
      "There are 1684 unique values\n",
      "<DatetimeArray>\n",
      "['2013-01-01 00:00:00', '2013-01-02 00:00:00', '2013-01-03 00:00:00',\n",
      " '2013-01-04 00:00:00', '2013-01-05 00:00:00', '2013-01-06 00:00:00',\n",
      " '2013-01-07 00:00:00', '2013-01-08 00:00:00', '2013-01-09 00:00:00',\n",
      " '2013-01-10 00:00:00',\n",
      " ...\n",
      " '2017-08-06 00:00:00', '2017-08-07 00:00:00', '2017-08-08 00:00:00',\n",
      " '2017-08-09 00:00:00', '2017-08-10 00:00:00', '2017-08-11 00:00:00',\n",
      " '2017-08-12 00:00:00', '2017-08-13 00:00:00', '2017-08-14 00:00:00',\n",
      " '2017-08-15 00:00:00']\n",
      "Length: 1684, dtype: datetime64[ns]\n",
      "______________________________________________________________________\n",
      "store_nbr\n",
      "There are 54 unique values\n",
      "[ 1 10 11 12 13 14 15 16 17 18 19  2 20 21 22 23 24 25 26 27 28 29  3 30\n",
      " 31 32 33 34 35 36 37 38 39  4 40 41 42 43 44 45 46 47 48 49  5 50 51 52\n",
      " 53 54  6  7  8  9]\n",
      "______________________________________________________________________\n",
      "family\n",
      "There are 33 unique values\n",
      "['AUTOMOTIVE' 'BABY CARE' 'BEAUTY' 'BEVERAGES' 'BOOKS' 'BREAD/BAKERY'\n",
      " 'CELEBRATION' 'CLEANING' 'DAIRY' 'DELI' 'EGGS' 'FROZEN FOODS' 'GROCERY I'\n",
      " 'GROCERY II' 'HARDWARE' 'HOME AND KITCHEN I' 'HOME AND KITCHEN II'\n",
      " 'HOME APPLIANCES' 'HOME CARE' 'LADIESWEAR' 'LAWN AND GARDEN' 'LINGERIE'\n",
      " 'LIQUOR,WINE,BEER' 'MAGAZINES' 'MEATS' 'PERSONAL CARE' 'PET SUPPLIES'\n",
      " 'PLAYERS AND ELECTRONICS' 'POULTRY' 'PREPARED FOODS' 'PRODUCE'\n",
      " 'SCHOOL AND OFFICE SUPPLIES' 'SEAFOOD']\n",
      "______________________________________________________________________\n",
      "sales\n",
      "There are 379610 unique values\n",
      "[0.000000e+00 2.000000e+00 8.100000e+02 ... 4.381330e+02 1.545530e+02\n",
      " 2.419729e+03]\n",
      "______________________________________________________________________\n",
      "onpromotion\n",
      "There are 362 unique values\n",
      "[  0   3   5   1  56  20  19   2   4  18  17  12   6   7  10   9  50   8\n",
      "  16  42  51  13  15  47  21  40  37  54  24  58  22  59  11  45  25  55\n",
      "  26  43  35  14  28  46  36  32  53  57  27  39  41  30  29  49  23  48\n",
      "  44  38  31  52  33  34  61  60 116  86  73 113 102  68 104  93  70  92\n",
      " 121  72 178 174 161 118 105 172 163 167 142 154 133 180 181 173 165 168\n",
      " 186 140 149 145 169 188  62  84 111  65 107  63 101  87 125  94 114 171\n",
      " 153 170 166 141 155 179 192 131 147 151 189  79  74 110  64  67  99 123\n",
      " 157 117 150 182 162 160 194 135 190  69 108  89 126 156 103 146 132 177\n",
      " 164 176 112  75 109  91 128 175 187 148 137 184 196 144 158 119 106  66\n",
      " 100  90 120 115  98 159 152 185 139 143  80 124  71 134 193  78  88 122\n",
      " 130  81  97 138 191  76  96 198  82  95 195 183 199 200 201 197  77  83\n",
      " 136 205 204 202 129 206  85 209 211 207 208 203 210 127 213 212 218 216\n",
      " 217 214 222 220 223 229 225 228 224 231 215 233 230 235 227 221 226 219\n",
      " 289 245 609 261 322 276 710 511 326 281 718 551 304 639 489 299 243 630\n",
      " 476 655 446 286 633 435 302 644 470 332 259 702 520 300 241 668 510 237\n",
      " 626 507 317 624 474 240 672 306 600 383 293 258 646 444 333 279 717 342\n",
      " 720 547 305 642 452 313 252 664 481 277 307 264 684 479 255 657 441 312\n",
      " 269 716 528 320 285 726 536 283 628 469 464 677 420 247 629 424 290 473\n",
      " 294 722 485 297 282 719 543 253 254 678 496 275 741 512 236 234 244 239\n",
      " 238 242 232 249 250 251 391 539 411 486 407 330 697 246 467 263 591 248\n",
      " 519 425]\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for column in columns:\n",
    "    print(f'{column}')\n",
    "    print(f'There are {df_train_eda[column].unique().size} unique values')\n",
    "    print(f'{df_train_eda[column].unique()}')\n",
    "    print('_' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <td>3000888.0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>15.585787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>3000888.0</td>\n",
       "      <td>357.775749</td>\n",
       "      <td>1101.997721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>195.84725</td>\n",
       "      <td>124717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onpromotion</th>\n",
       "      <td>3000888.0</td>\n",
       "      <td>2.602770</td>\n",
       "      <td>12.218882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count        mean          std  min   25%   50%        75%  \\\n",
       "store_nbr    3000888.0   27.500000    15.585787  1.0  14.0  27.5   41.00000   \n",
       "sales        3000888.0  357.775749  1101.997721  0.0   0.0  11.0  195.84725   \n",
       "onpromotion  3000888.0    2.602770    12.218882  0.0   0.0   0.0    0.00000   \n",
       "\n",
       "                  max  \n",
       "store_nbr        54.0  \n",
       "sales        124717.0  \n",
       "onpromotion     741.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eda[['store_nbr', 'sales', 'onpromotion']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>3000888</td>\n",
       "      <td>33</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>90936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique         top   freq\n",
       "family  3000888     33  AUTOMOTIVE  90936"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eda.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
